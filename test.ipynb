{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salu-dduck/salu-dduck.github.io/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 가져오기\n"
      ],
      "metadata": {
        "id": "sHKLCIjit6nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1-3QwjsTlDLGuK0JYU_XbweNkaKfnyMmW&export=download\n",
        "!unzip 컴퓨터비전_09YOLOv8_deadchicken.zip\n",
        "!rm 컴퓨터비전_09YOLOv8_deadchicken.zip"
      ],
      "metadata": {
        "id": "Yp4VcR8q5bGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22083e61-9993-421b-cabf-fe9e92027935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/u/0/uc?id=1-3QwjsTlDLGuK0JYU_XbweNkaKfnyMmW\n",
            "From (redirected): https://drive.google.com/uc?id=1-3QwjsTlDLGuK0JYU_XbweNkaKfnyMmW&confirm=t&uuid=4c9591fd-6634-413b-90c3-8e461afcd8e7\n",
            "To: /content/컴퓨터비전_09YOLOv8_deadchicken.zip\n",
            "100% 65.5M/65.5M [00:00<00:00, 219MB/s]\n",
            "Archive:  컴퓨터비전_09YOLOv8_deadchicken.zip\n",
            "replace best.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv8 설치"
      ],
      "metadata": {
        "id": "FznUXOjJpsZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "oj_ZIMM5pzTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bacfc4-199e-4cc3-e047-277071cd59ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.174)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV 설치"
      ],
      "metadata": {
        "id": "DJYLZTiOqhhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python"
      ],
      "metadata": {
        "id": "fcf9XATwqlXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv8을 이용하여 이미지에서 객체 탐색"
      ],
      "metadata": {
        "id": "Ju58S9NFqzKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a COCO-pretrained YOLOv8n model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Run batched inference on a list of images\n",
        "results = model([\"./images/image1.jpg\", \"./images/image2.jpg\", \"./images/image3.jpg\"])  # return a list of Results objects\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen"
      ],
      "metadata": {
        "id": "5LhDJtsJrR3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab 환경에서는 실행되도록 수정하여 Colab에서 실행됨"
      ],
      "metadata": {
        "id": "tE00sRIi-R5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intel OpenMP 런타임 라이브러리(libiomp5md.dll)가 이미 초기화된 상태에서 다시 초기화하려 할 때 발생하는 오류 해결\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
        "#model = YOLO(\"./best.pt\")\n",
        "\n",
        "cap = cv2.VideoCapture(\"./images/0_8_IPC1_20230108162038_04.mp4\")\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 250 != 0:  # Colab에서 10초당 1회만 출력하기 위해\n",
        "        continue\n",
        "\n",
        "    roi_frame = frame[800:1600, 700:1800].copy()  # 2880x1624 사이즈에서 관심영역만 추출\n",
        "\n",
        "    results = model.predict(roi_frame, conf=0.6, show=False)\n",
        "\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = box.conf[0]\n",
        "            cls = int(box.cls[0])\n",
        "            cv2.rectangle(roi_frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "            str_id = f\"{model.names[cls]} {conf:.2f}\"\n",
        "            cv2.putText(roi_frame, str_id, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
        "\n",
        "    cv2_imshow(roi_frame)\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "MUWRRU74-ZZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VSCode에서 실행할 수 있는 코드\n",
        "- Colab 환경에서는 실행 안됨"
      ],
      "metadata": {
        "id": "QQr2nqBe-OLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intel OpenMP 런타임 라이브러리(libiomp5md.dll)가 이미 초기화된 상태에서 다시 초기화하려 할 때 발생하는 오류 해결\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
        "#model = YOLO(\"./best.pt\")\n",
        "\n",
        "cap = cv2.VideoCapture(\"./images/0_8_IPC1_20230108162038_04.mp4\")\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count > 200 : break\n",
        "    roi_frame = frame[800:1600, 700:1800].copy()  # 2880x1624 사이즈에서 관심영역만 추출\n",
        "\n",
        "    results = model.predict(roi_frame, conf=0.6, show=False)\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = box.conf[0]\n",
        "            cls = int(box.cls[0])\n",
        "            cv2.rectangle(roi_frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "            str_id = f\"{model.names[cls]} {conf:.2f}\"\n",
        "            cv2.putText(roi_frame, str_id, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
        "\n",
        "    cv2.imshow(\"Object Detection\", roi_frame)\n",
        "\n",
        "    if cv2.waitKey(40) & 0xFF == ord('q'): # 키 입력 처리 (q: 종료)\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "eudNSYLk-Ei9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "results = model('/content/stud')\n",
        "\n",
        "for result in results:\n",
        "  result.show()\n"
      ],
      "metadata": {
        "id": "e1d1R4bz29lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "files = os.listdir('./stud')\n",
        "print(files)"
      ],
      "metadata": {
        "id": "8xMJAdeb3cAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "files = os.listdir('./stud')\n",
        "image_paths = ['./stud/' + f for f in files]\n",
        "\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "results = model(image_paths)\n",
        "\n",
        "for result in results:\n",
        "  result.show()"
      ],
      "metadata": {
        "id": "Gouz74LhW6KK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 이미지 경로\n",
        "image_paths = ['./stud/' + f for f in os.listdir('./stud') if f.lower().endswith('박한별.jpg')]\n",
        "\n",
        "# 모델 로드 및 추론\n",
        "model = YOLO('yolov8n.pt')\n",
        "results = model(image_paths)\n",
        "\n",
        "# 감지된 클래스 이름 출력\n",
        "for result in results:\n",
        "    classes = set(int(cls) for cls in result.boxes.cls)\n",
        "    for cls_id in classes:\n",
        "        print(result.names[cls_id])"
      ],
      "metadata": {
        "id": "Ck7q0KOIbovE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "#results = model.predict('/content/stud/apple1 (1).png',)\n",
        "#results = model.predict('/content/images/apple1.jpg',)\n",
        "#model.predict(source='/content/stud/apple1 (1).png',conf=0.1, show=True)\n",
        "#model.predict(source='/content/stud/apple1 (1).png',iou=0.3)\n",
        "\n",
        "results = model.predict(source='/content/stud/apple1 (1).png',  verbose=True)\n",
        "\n",
        "for result in results:\n",
        "    result.show()"
      ],
      "metadata": {
        "id": "xOhOCy3FesoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "#results = model.predict('/content/stud/apple1 (1).png',)\n",
        "#results = model.predict('/content/images/apple1.jpg',)\n",
        "#model.predict(source='/content/stud/apple1 (1).png',conf=0.1, show=True)\n",
        "#model.predict(source='/content/stud/apple1 (1).png',iou=0.3)\n",
        "\n",
        "results = model.predict(source='/content/stud/apple1 (1).png',  verbose=True)\n",
        "\n",
        "for result in results:\n",
        "    result.show()"
      ],
      "metadata": {
        "id": "0crqJ111u5ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github 운영을 해보기\n",
        "#https://jjmoak2.iwinv.net/wp/?p=16954"
      ],
      "metadata": {
        "id": "WcqwfEzxg8mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im1 = result[0].orig_img\n",
        "im2 = result[0].plot()\n",
        "\n",
        "plt.imshow(im1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xacxViniuMhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  #이미지 시각화를 위한 matplotlib의 pyplot 모듈 불러오기\n",
        "import cv2  # 이미지 처리용 OpenCV 라이브러리 불러오기\n",
        "\n",
        "im1 = result[0].orig_img # YOLO 추론 결과 중 원본 이미지(BGR 형식)를 가져옴\n",
        "im2 = result[0].plot() # 감지 결과(바운딩박스 등 포함된 이미지, RGB 형식)를 가져옴\n",
        "\n",
        "im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)  # OpenCV 이미지(BGR)를 matplotlib용 RGB로 변환 (이미 RGB일 수도 있지만 안정성을 위해 변환)\n",
        "\n",
        "plt.imshow(im2) #출력\n",
        "plt.show() #이미지 시각화\n",
        "\n",
        "#항목\t색상 순서\n",
        "#im1\tBGR (OpenCV 기본)\n",
        "#im2\tRGB (Matplotlib용으로 이미 변환됨)"
      ],
      "metadata": {
        "id": "s7WcTwJ20k-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "9ZdxsUVy2IwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  #이미지 시각화를 위한 matplotlib의 pyplot 모듈 불러오기\n",
        "import cv2  # 이미지 처리용 OpenCV 라이브러리 불러오기\n",
        "\n",
        "im1 = result[0].orig_img # YOLO 추론 결과 중 원본 이미지(BGR 형식)를 가져옴\n",
        "im2 = result[0].plot() # 감지 결과(바운딩박스 등 포함된 이미지, RGB 형식)를 가져옴\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)) #출력\n",
        "plt.show() #이미지 시각화\n",
        "\n",
        "plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)) #출력\n",
        "plt.show() #이미지 시각화\n",
        "\n",
        "#항목\t색상 순서\n",
        "#im1\tBGR (OpenCV 기본)\n",
        "#im2\tRGB (Matplotlib용으로 이미 변환됨)"
      ],
      "metadata": {
        "id": "_8KH5nY42JR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  #이미지 시각화를 위한 matplotlib의 pyplot 모듈 불러오기\n",
        "import cv2  # 이미지 처리용 OpenCV 라이브러리 불러오기\n",
        "\n",
        "im1 = result[0].orig_img # YOLO 추론 결과 중 원본 이미지(BGR 형식)를 가져옴\n",
        "im2 = result[0].plot() # 감지 결과(바운딩박스 등 포함된 이미지, RGB 형식)를 가져옴\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L9Fni_WyACsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO  # Ultralytics YOLOv8 모델 클래스 임포트\n",
        "import matplotlib.pyplot as plt  # 이미지 시각화용 matplotlib 불러오기\n",
        "import cv2  # OpenCV: 이미지 색상 변환 등 다양한 이미지 처리 기능 제공\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "#results = model.predict('/content/stud/apple1 (1).png')\n",
        "results = model([\"./images/image1.jpg\", \"./images/image2.jpg\", \"./images/image3.jpg\"])\n",
        "\n",
        "for result in results:  # 여러 이미지일 경우를 대비한 반복문 (현재는 1장만 처리됨)\n",
        "  im1 = result.orig_img  # 원본 이미지(BGR) 가져오기 (추론 전의 입력 이미지)\n",
        "  im2 = result.plot()    # 감지된 객체가 표시된 이미지 (바운딩 박스, 라벨 등 포함, RGB 형식)\n",
        "\n",
        "  plt.figure(figsize=(8, 4))  # 그림 크기 설정 (가로 8인치, 세로 4인치)\n",
        "\n",
        "  plt.subplot(1, 2, 1)  # 1행 2열 중 첫 번째(왼쪽) 영역 지정\n",
        "  plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB))  # OpenCV의 BGR 이미지를 RGB로 변환하여 표시\n",
        "  plt.axis('off')  # 축 및 눈금 제거 (더 깔끔한 이미지 표시)\n",
        "\n",
        "  plt.subplot(1, 2, 2)  # 1행 2열 중 두 번째(오른쪽) 영역 지정\n",
        "  plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))  # 감지 결과 이미지도 RGB로 변환하여 표시\n",
        "  plt.axis('off')  # 축 제거\n",
        "\n",
        "  plt.show()  # 위에서 설정한 두 개의 subplot(원본, 결과)을 화면에 출력\n"
      ],
      "metadata": {
        "id": "bt_aOOaxAT9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "#results = model.predict('/content/stud/apple1 (1).png')\n",
        "results = model([\"./images/image1.jpg\", \"./images/image2.jpg\", \"./images/image3.jpg\"])\n",
        "\n",
        "for result in results:\n",
        "  im3 = result.orig_img.copy()\n",
        "  for box, conf in zip(result.boxes.xyxy, result.boxes.conf):\n",
        "    print(box, f\"{conf.item():.2f}\")\n",
        "    x1, y1, x2, y2 = [int(p) for p in box]\n",
        "    cv2.rectangle(im3, (x1, y1), (x2, y2), (0,0,255), 2)\n",
        "    cv2.putText(im3, msg, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "  plt.imshow(cv2.cvtColor(im3, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "CGvbq8paDVrK",
        "outputId": "6fb2f761-5815-4fba-fd0c-1e42a0c52901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 1 person, 3 cars, 1 skateboard, 264.8ms\n",
            "1: 640x640 1 person, 1 car, 264.8ms\n",
            "2: 640x640 1 banana, 1 apple, 264.8ms\n",
            "Speed: 18.1ms preprocess, 264.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([ 73.5102, 102.7018, 123.1479, 204.2951]) 0.90\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'msg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2445062614.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'msg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums = [1,2,3]\n",
        "\n",
        "for num in nums:\n",
        "  print(num)"
      ],
      "metadata": {
        "id": "EDj7gH_aHRNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc50123-e084-4873-83c5-cf39ea3d8d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums = [1,2,3]\n",
        "hs = [170,180,190]\n",
        "\n",
        "# for num in nums:\n",
        "#   print(num)\n",
        "\n",
        "# for h in hs:\n",
        "#   print(h)\n",
        "\n",
        "for num in nums:\n",
        "  for h in hs:\n",
        "    print(num, h)"
      ],
      "metadata": {
        "id": "Iga3hchmsYA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ms = [2,3,4,5,6,7,8,9]\n",
        "ns = [1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "for m in ms:\n",
        "  print('\\n',m,'단')\n",
        "  for n in ns:\n",
        "#    print(m,'x', n, '=', m*n)\n",
        "    print(f\"{m} x {n} = {m*n}\")\n",
        "    print(f\"{m:1d} x {n:1d} = {m*n:2d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lQx-XJLytEAa",
        "outputId": "99cda2e0-9b33-4d98-909f-4413de886df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 2 단\n",
            "2 x 1 = 2\n",
            "2 x 1 =  2\n",
            "2 x 2 = 4\n",
            "2 x 2 =  4\n",
            "2 x 3 = 6\n",
            "2 x 3 =  6\n",
            "2 x 4 = 8\n",
            "2 x 4 =  8\n",
            "2 x 5 = 10\n",
            "2 x 5 = 10\n",
            "2 x 6 = 12\n",
            "2 x 6 = 12\n",
            "2 x 7 = 14\n",
            "2 x 7 = 14\n",
            "2 x 8 = 16\n",
            "2 x 8 = 16\n",
            "2 x 9 = 18\n",
            "2 x 9 = 18\n",
            "\n",
            " 3 단\n",
            "3 x 1 = 3\n",
            "3 x 1 =  3\n",
            "3 x 2 = 6\n",
            "3 x 2 =  6\n",
            "3 x 3 = 9\n",
            "3 x 3 =  9\n",
            "3 x 4 = 12\n",
            "3 x 4 = 12\n",
            "3 x 5 = 15\n",
            "3 x 5 = 15\n",
            "3 x 6 = 18\n",
            "3 x 6 = 18\n",
            "3 x 7 = 21\n",
            "3 x 7 = 21\n",
            "3 x 8 = 24\n",
            "3 x 8 = 24\n",
            "3 x 9 = 27\n",
            "3 x 9 = 27\n",
            "\n",
            " 4 단\n",
            "4 x 1 = 4\n",
            "4 x 1 =  4\n",
            "4 x 2 = 8\n",
            "4 x 2 =  8\n",
            "4 x 3 = 12\n",
            "4 x 3 = 12\n",
            "4 x 4 = 16\n",
            "4 x 4 = 16\n",
            "4 x 5 = 20\n",
            "4 x 5 = 20\n",
            "4 x 6 = 24\n",
            "4 x 6 = 24\n",
            "4 x 7 = 28\n",
            "4 x 7 = 28\n",
            "4 x 8 = 32\n",
            "4 x 8 = 32\n",
            "4 x 9 = 36\n",
            "4 x 9 = 36\n",
            "\n",
            " 5 단\n",
            "5 x 1 = 5\n",
            "5 x 1 =  5\n",
            "5 x 2 = 10\n",
            "5 x 2 = 10\n",
            "5 x 3 = 15\n",
            "5 x 3 = 15\n",
            "5 x 4 = 20\n",
            "5 x 4 = 20\n",
            "5 x 5 = 25\n",
            "5 x 5 = 25\n",
            "5 x 6 = 30\n",
            "5 x 6 = 30\n",
            "5 x 7 = 35\n",
            "5 x 7 = 35\n",
            "5 x 8 = 40\n",
            "5 x 8 = 40\n",
            "5 x 9 = 45\n",
            "5 x 9 = 45\n",
            "\n",
            " 6 단\n",
            "6 x 1 = 6\n",
            "6 x 1 =  6\n",
            "6 x 2 = 12\n",
            "6 x 2 = 12\n",
            "6 x 3 = 18\n",
            "6 x 3 = 18\n",
            "6 x 4 = 24\n",
            "6 x 4 = 24\n",
            "6 x 5 = 30\n",
            "6 x 5 = 30\n",
            "6 x 6 = 36\n",
            "6 x 6 = 36\n",
            "6 x 7 = 42\n",
            "6 x 7 = 42\n",
            "6 x 8 = 48\n",
            "6 x 8 = 48\n",
            "6 x 9 = 54\n",
            "6 x 9 = 54\n",
            "\n",
            " 7 단\n",
            "7 x 1 = 7\n",
            "7 x 1 =  7\n",
            "7 x 2 = 14\n",
            "7 x 2 = 14\n",
            "7 x 3 = 21\n",
            "7 x 3 = 21\n",
            "7 x 4 = 28\n",
            "7 x 4 = 28\n",
            "7 x 5 = 35\n",
            "7 x 5 = 35\n",
            "7 x 6 = 42\n",
            "7 x 6 = 42\n",
            "7 x 7 = 49\n",
            "7 x 7 = 49\n",
            "7 x 8 = 56\n",
            "7 x 8 = 56\n",
            "7 x 9 = 63\n",
            "7 x 9 = 63\n",
            "\n",
            " 8 단\n",
            "8 x 1 = 8\n",
            "8 x 1 =  8\n",
            "8 x 2 = 16\n",
            "8 x 2 = 16\n",
            "8 x 3 = 24\n",
            "8 x 3 = 24\n",
            "8 x 4 = 32\n",
            "8 x 4 = 32\n",
            "8 x 5 = 40\n",
            "8 x 5 = 40\n",
            "8 x 6 = 48\n",
            "8 x 6 = 48\n",
            "8 x 7 = 56\n",
            "8 x 7 = 56\n",
            "8 x 8 = 64\n",
            "8 x 8 = 64\n",
            "8 x 9 = 72\n",
            "8 x 9 = 72\n",
            "\n",
            " 9 단\n",
            "9 x 1 = 9\n",
            "9 x 1 =  9\n",
            "9 x 2 = 18\n",
            "9 x 2 = 18\n",
            "9 x 3 = 27\n",
            "9 x 3 = 27\n",
            "9 x 4 = 36\n",
            "9 x 4 = 36\n",
            "9 x 5 = 45\n",
            "9 x 5 = 45\n",
            "9 x 6 = 54\n",
            "9 x 6 = 54\n",
            "9 x 7 = 63\n",
            "9 x 7 = 63\n",
            "9 x 8 = 72\n",
            "9 x 8 = 72\n",
            "9 x 9 = 81\n",
            "9 x 9 = 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in range(2,10):\n",
        "  print(f\"{m}단\")\n",
        "  for n in range(1,10):\n",
        "    print(f\"{m:1d} x {n:1d} = {m*n:2d}\")\n",
        "\n",
        "    #range(시작,끝,증감)\n",
        "    #기본값(0,끝,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCO2irLwtm9k",
        "outputId": "4d64e333-600a-46a1-b1de-3c83328dd6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2단\n",
            "2 x 1 =  2\n",
            "2 x 2 =  4\n",
            "2 x 3 =  6\n",
            "2 x 4 =  8\n",
            "2 x 5 = 10\n",
            "2 x 6 = 12\n",
            "2 x 7 = 14\n",
            "2 x 8 = 16\n",
            "2 x 9 = 18\n",
            "3단\n",
            "3 x 1 =  3\n",
            "3 x 2 =  6\n",
            "3 x 3 =  9\n",
            "3 x 4 = 12\n",
            "3 x 5 = 15\n",
            "3 x 6 = 18\n",
            "3 x 7 = 21\n",
            "3 x 8 = 24\n",
            "3 x 9 = 27\n",
            "4단\n",
            "4 x 1 =  4\n",
            "4 x 2 =  8\n",
            "4 x 3 = 12\n",
            "4 x 4 = 16\n",
            "4 x 5 = 20\n",
            "4 x 6 = 24\n",
            "4 x 7 = 28\n",
            "4 x 8 = 32\n",
            "4 x 9 = 36\n",
            "5단\n",
            "5 x 1 =  5\n",
            "5 x 2 = 10\n",
            "5 x 3 = 15\n",
            "5 x 4 = 20\n",
            "5 x 5 = 25\n",
            "5 x 6 = 30\n",
            "5 x 7 = 35\n",
            "5 x 8 = 40\n",
            "5 x 9 = 45\n",
            "6단\n",
            "6 x 1 =  6\n",
            "6 x 2 = 12\n",
            "6 x 3 = 18\n",
            "6 x 4 = 24\n",
            "6 x 5 = 30\n",
            "6 x 6 = 36\n",
            "6 x 7 = 42\n",
            "6 x 8 = 48\n",
            "6 x 9 = 54\n",
            "7단\n",
            "7 x 1 =  7\n",
            "7 x 2 = 14\n",
            "7 x 3 = 21\n",
            "7 x 4 = 28\n",
            "7 x 5 = 35\n",
            "7 x 6 = 42\n",
            "7 x 7 = 49\n",
            "7 x 8 = 56\n",
            "7 x 9 = 63\n",
            "8단\n",
            "8 x 1 =  8\n",
            "8 x 2 = 16\n",
            "8 x 3 = 24\n",
            "8 x 4 = 32\n",
            "8 x 5 = 40\n",
            "8 x 6 = 48\n",
            "8 x 7 = 56\n",
            "8 x 8 = 64\n",
            "8 x 9 = 72\n",
            "9단\n",
            "9 x 1 =  9\n",
            "9 x 2 = 18\n",
            "9 x 3 = 27\n",
            "9 x 4 = 36\n",
            "9 x 5 = 45\n",
            "9 x 6 = 54\n",
            "9 x 7 = 63\n",
            "9 x 8 = 72\n",
            "9 x 9 = 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ms = ['가', '나', '다', '라']\n",
        "ns = ['A', 'B', 'C', 'D']\n",
        "ss = [['가','A'], ['나','B'], ['다','C'], ['라','D']]\n",
        "\n",
        "# for m in ms:\n",
        "#   print(m)\n",
        "\n",
        "# for n in ns:\n",
        "#   print(n)\n",
        "\n",
        "for s in ss:\n",
        "  print(s)\n",
        "\n",
        "for m, n in ss:\n",
        "  print(m, n)\n",
        "\n",
        "for m, n in zip(ms,ns):\n",
        "  print(m,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTNLjuzTxsft",
        "outputId": "d4fc8b49-b267-4528-a0a6-dec26fa12b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['가', 'A']\n",
            "['나', 'B']\n",
            "['다', 'C']\n",
            "['라', 'D']\n",
            "가 A\n",
            "나 B\n",
            "다 C\n",
            "라 D\n",
            "가 A\n",
            "나 B\n",
            "다 C\n",
            "라 D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  #이미지 시각화를 위한 matplotlib의 pyplot 모듈 불러오기\n",
        "import cv2  # 이미지 처리용 OpenCV 라이브러리 불러오기\n",
        "\n",
        "im1 = result[0].orig_img # YOLO 추론 결과 중 원본 이미지(BGR 형식)를 가져옴\n",
        "im2 = result[0].plot() # 감지 결과(바운딩박스 등 포함된 이미지, RGB 형식)를 가져옴\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "jaEVU5Ty00pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO  # Ultralytics YOLOv8 모델 클래스 임포트\n",
        "import matplotlib.pyplot as plt  # 이미지 시각화용 matplotlib 불러오기\n",
        "import cv2  # OpenCV: 이미지 색상 변환 등 다양한 이미지 처리 기능 제공\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "#results = model.predict('/content/stud/apple1 (1).png')\n",
        "results = model([\"./images/image1.jpg\", \"./images/image2.jpg\", \"./images/image3.jpg\"])\n",
        "\n",
        "for result in results:  # 여러 이미지일 경우를 대비한 반복문 (현재는 1장만 처리됨)\n",
        "  im1 = result.orig_img  # 원본 이미지(BGR) 가져오기 (추론 전의 입력 이미지)\n",
        "  im2 = result.plot()    # 감지된 객체가 표시된 이미지 (바운딩 박스, 라벨 등 포함, RGB 형식)\n",
        "  im3 = result.orig_img.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(8, 4))  # 그림 크기 설정 (가로 8인치, 세로 4인치)\n",
        "\n",
        "  plt.subplot(1, 3, 1)  # 1행 2열 중 첫 번째(왼쪽) 영역 지정\n",
        "  plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB))  # OpenCV의 BGR 이미지를 RGB로 변환하여 표시\n",
        "  plt.axis('off')  # 축 및 눈금 제거 (더 깔끔한 이미지 표시)\n",
        "\n",
        "  plt.subplot(1, 3, 2)  # 1행 2열 중 두 번째(오른쪽) 영역 지정\n",
        "  plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))  # 감지 결과 이미지도 RGB로 변환하여 표시\n",
        "  plt.axis('off')  # 축 제거\n",
        "\n",
        "    plt.subplot(1, 3, 3)  # 1행 2열 중 두 번째(오른쪽) 영역 지정\n",
        "  plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))  # 감지 결과 이미지도 RGB로 변환하여 표시\n",
        "  plt.axis('off')  # 축 제거\n",
        "\n",
        "  plt.show()  # 위에서 설정한 두 개의 subplot(원본, 결과)을 화면에 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "NUIJd_ro6M3j",
        "outputId": "671b9a92-706f-4c21-c328-df948341dd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-3292334491.py, line 28)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3292334491.py\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    plt.subplot(1, 3, 3)  # 1행 2열 중 두 번째(오른쪽) 영역 지정\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qY1U-az61iN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}